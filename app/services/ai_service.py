"""
AI åˆ†ææœåŠ¡
ä½¿ç”¨ OpenAI API æˆ–æœ¬åœ° Ollama è¿›è¡Œæ™ºèƒ½åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import json
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime

import httpx
from app.core.config import get_settings
from app.core.logger import get_logger

logger = get_logger(__name__)


class AIService:
    """AI åˆ†ææœåŠ¡"""
    
    def __init__(self):
        self.settings = get_settings()
        self.ai_config = self.settings.ai
        
    async def generate_repository_summary(self, analysis_data: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆä»“åº“æ´»åŠ¨æ‘˜è¦ï¼ˆæ–°ç‰ˆæœ¬ï¼Œæ”¯æŒæŠ¥å‘Šç”Ÿæˆï¼‰
        
        Args:
            analysis_data: åŒ…å«ä»“åº“ä¿¡æ¯ã€æäº¤ã€issuesã€PRç­‰çš„åˆ†ææ•°æ®
        
        Returns:
            str: ç”Ÿæˆçš„æ‘˜è¦
        """
        try:
            if self.ai_config.provider == "openai" and self.ai_config.openai_api_key:
                return await self._generate_openai_repository_summary(analysis_data)
            elif self.ai_config.provider == "ollama":
                return await self._generate_ollama_repository_summary(analysis_data)
            else:
                return self._generate_simple_repository_summary(analysis_data)
        except Exception as e:
            logger.error(f"ğŸ’¥ ç”Ÿæˆä»“åº“æ‘˜è¦å¤±è´¥: {e}")
            return self._generate_simple_repository_summary(analysis_data)

    async def analyze_repository_trends(self, analysis_data: Dict[str, Any]) -> str:
        """
        åˆ†æä»“åº“è¶‹åŠ¿
        
        Args:
            analysis_data: åŒ…å«ä»“åº“ä¿¡æ¯ã€æäº¤ã€issuesã€PRç­‰çš„åˆ†ææ•°æ®
        
        Returns:
            str: ç”Ÿæˆçš„è¶‹åŠ¿åˆ†æ
        """
        try:
            if self.ai_config.provider == "openai" and self.ai_config.openai_api_key:
                return await self._generate_openai_trend_analysis(analysis_data)
            elif self.ai_config.provider == "ollama":
                return await self._generate_ollama_trend_analysis(analysis_data)
            else:
                return self._generate_simple_trend_analysis(analysis_data)
        except Exception as e:
            logger.error(f"ğŸ’¥ ç”Ÿæˆè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return self._generate_simple_trend_analysis(analysis_data)

    async def _generate_openai_repository_summary(self, analysis_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨ OpenAI ç”Ÿæˆä»“åº“æ‘˜è¦"""
        try:
            prompt = self._create_repository_summary_prompt(analysis_data)
            
            request_data = {
                "model": self.ai_config.openai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„GitHubä»“åº“åˆ†æå¸ˆï¼Œæ“…é•¿æ€»ç»“ä»“åº“æ´»åŠ¨å¹¶æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€ç®€æ´æ˜äº†ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": self.ai_config.max_tokens,
                "temperature": self.ai_config.temperature
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.ai_config.openai_api_key}",
                        "Content-Type": "application/json"
                    },
                    json=request_data,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    result = response.json()
                    summary = result["choices"][0]["message"]["content"].strip()
                    logger.info(f"âœ… OpenAI ä»“åº“æ‘˜è¦ç”ŸæˆæˆåŠŸ")
                    return summary
                else:
                    logger.error(f"ğŸ’¥ OpenAI API è¯·æ±‚å¤±è´¥: {response.status_code}")
                    return self._generate_simple_repository_summary(analysis_data)
                    
        except Exception as e:
            logger.error(f"ğŸ’¥ OpenAI ä»“åº“æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_simple_repository_summary(analysis_data)

    async def _generate_openai_trend_analysis(self, analysis_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨ OpenAI ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        try:
            prompt = self._create_trend_analysis_prompt(analysis_data)
            
            request_data = {
                "model": self.ai_config.openai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶å¼€å‘è¶‹åŠ¿åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æä»£ç ä»“åº“çš„å‘å±•è¶‹åŠ¿å’Œæä¾›æ”¹è¿›å»ºè®®ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæä¾›å…·ä½“å¯è¡Œçš„å»ºè®®ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": self.ai_config.max_tokens,
                "temperature": self.ai_config.temperature
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.ai_config.openai_api_key}",
                        "Content-Type": "application/json"
                    },
                    json=request_data,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    result = response.json()
                    analysis = result["choices"][0]["message"]["content"].strip()
                    logger.info(f"âœ… OpenAI è¶‹åŠ¿åˆ†æç”ŸæˆæˆåŠŸ")
                    return analysis
                else:
                    logger.error(f"ğŸ’¥ OpenAI API è¯·æ±‚å¤±è´¥: {response.status_code}")
                    return self._generate_simple_trend_analysis(analysis_data)
                    
        except Exception as e:
            logger.error(f"ğŸ’¥ OpenAI è¶‹åŠ¿åˆ†æç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_simple_trend_analysis(analysis_data)

    def _create_repository_summary_prompt(self, analysis_data: Dict[str, Any]) -> str:
        """åˆ›å»ºä»“åº“æ‘˜è¦çš„æç¤ºè¯"""
        repo = analysis_data.get('repository', {})
        commits = analysis_data.get('commits', [])
        issues = analysis_data.get('issues', [])
        prs = analysis_data.get('pull_requests', [])
        releases = analysis_data.get('releases', [])
        period = analysis_data.get('period', {})
        
        # æ„å»ºè¯¦ç»†çš„æ´»åŠ¨ä¿¡æ¯
        commits_info = ""
        if commits:
            commits_info = "\næœ€è¿‘çš„æäº¤:\n"
            for i, commit in enumerate(commits[:5]):  # æ˜¾ç¤ºå‰5ä¸ªæäº¤
                commits_info += f"- {commit.get('message', 'æ— æ¶ˆæ¯')[:80]}... (ä½œè€…: {commit.get('author', {}).get('name', 'æœªçŸ¥')})\n"
        
        issues_info = ""
        if issues:
            issues_info = "\næœ€è¿‘çš„Issues:\n"
            for i, issue in enumerate(issues[:5]):  # æ˜¾ç¤ºå‰5ä¸ªissues
                state = issue.get('state', 'unknown')
                issues_info += f"- [{state.upper()}] {issue.get('title', 'æ— æ ‡é¢˜')[:60]}... (ä½œè€…: {issue.get('user', {}).get('login', 'æœªçŸ¥')})\n"
        
        prs_info = ""
        if prs:
            prs_info = "\næœ€è¿‘çš„Pull Requests:\n"
            for i, pr in enumerate(prs[:5]):  # æ˜¾ç¤ºå‰5ä¸ªPR
                state = pr.get('state', 'unknown')
                merged = pr.get('merged', False)
                status = "MERGED" if merged else state.upper()
                prs_info += f"- [{status}] {pr.get('title', 'æ— æ ‡é¢˜')[:60]}... (ä½œè€…: {pr.get('user', {}).get('login', 'æœªçŸ¥')})\n"
        
        releases_info = ""
        if releases:
            releases_info = "\næœ€è¿‘çš„å‘å¸ƒ:\n"
            for release in releases[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå‘å¸ƒ
                releases_info += f"- {release.get('tag_name', 'æœªçŸ¥ç‰ˆæœ¬')}: {release.get('name', 'æ— åç§°')}\n"
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹GitHubä»“åº“ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ´»åŠ¨æ‘˜è¦ï¼š

ä»“åº“ä¿¡æ¯ï¼š
- åç§°ï¼š{repo.get('name', 'Unknown')}
- æè¿°ï¼š{repo.get('description', 'æ— æè¿°')}
- ä¸»è¦è¯­è¨€ï¼š{repo.get('language', 'æœªçŸ¥')}
- Starsï¼š{repo.get('stargazers_count', 0)}
- Forksï¼š{repo.get('forks_count', 0)}

æŠ¥å‘ŠæœŸé—´ï¼š{period.get('start', '')} åˆ° {period.get('end', '')} ({period.get('type', 'daily')} æŠ¥å‘Š)

æ´»åŠ¨ç»Ÿè®¡ï¼š
- æäº¤æ•°ï¼š{len(commits)}
- Issuesæ•°ï¼š{len(issues)}
- Pull Requestsæ•°ï¼š{len(prs)}
- å‘å¸ƒæ•°ï¼š{len(releases)}

{commits_info}
{issues_info}
{prs_info}
{releases_info}

è¯·åŸºäºä»¥ä¸Šè¯¦ç»†ä¿¡æ¯ç”Ÿæˆä¸€ä¸ª2-3å¥è¯çš„ç®€æ´æ‘˜è¦ï¼Œçªå‡ºæœ¬æœŸé—´çš„ä¸»è¦æ´»åŠ¨ã€å¼€å‘é‡ç‚¹å’Œé¡¹ç›®è¿›å±•ã€‚
"""
        return prompt

    def _create_trend_analysis_prompt(self, analysis_data: Dict[str, Any]) -> str:
        """åˆ›å»ºè¶‹åŠ¿åˆ†æçš„æç¤ºè¯"""
        repo = analysis_data.get('repository', {})
        commits = analysis_data.get('commits', [])
        issues = analysis_data.get('issues', [])
        prs = analysis_data.get('pull_requests', [])
        period = analysis_data.get('period', {})
        
        # åˆ†ææäº¤è€…
        committers = set()
        for commit in commits:
            author = commit.get('author')
            if author:
                # å¦‚æœ author æ˜¯å­—å…¸ï¼Œæå– login æˆ– name
                if isinstance(author, dict):
                    author_name = author.get('login') or author.get('name') or 'Unknown'
                else:
                    author_name = str(author)
                committers.add(author_name)
        
        # åˆ†æIssueçŠ¶æ€
        open_issues = sum(1 for issue in issues if issue.get('state') == 'open')
        closed_issues = len(issues) - open_issues
        
        # åˆ†æPRçŠ¶æ€
        open_prs = sum(1 for pr in prs if pr.get('state') == 'open')
        merged_prs = sum(1 for pr in prs if pr.get('merged'))
        
        # æ„å»ºè¯¦ç»†çš„æ´»åŠ¨ä¿¡æ¯
        commits_detail = ""
        if commits:
            commits_detail = "\næäº¤è¯¦æƒ…:\n"
            for commit in commits[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæäº¤
                commits_detail += f"- {commit.get('message', 'æ— æ¶ˆæ¯')[:60]}... (ä½œè€…: {commit.get('author', {}).get('name', 'æœªçŸ¥')})\n"
        
        issues_detail = ""
        if issues:
            issues_detail = "\nIssuesè¯¦æƒ…:\n"
            for issue in issues[:3]:  # æ˜¾ç¤ºå‰3ä¸ªissues
                state = issue.get('state', 'unknown')
                issues_detail += f"- [{state.upper()}] {issue.get('title', 'æ— æ ‡é¢˜')[:50]}... (ä½œè€…: {issue.get('user', {}).get('login', 'æœªçŸ¥')})\n"
        
        prs_detail = ""
        if prs:
            prs_detail = "\nPull Requestsè¯¦æƒ…:\n"
            for pr in prs[:3]:  # æ˜¾ç¤ºå‰3ä¸ªPR
                state = pr.get('state', 'unknown')
                merged = pr.get('merged', False)
                status = "MERGED" if merged else state.upper()
                prs_detail += f"- [{status}] {pr.get('title', 'æ— æ ‡é¢˜')[:50]}... (ä½œè€…: {pr.get('user', {}).get('login', 'æœªçŸ¥')})\n"
        
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹GitHubä»“åº“çš„å‘å±•è¶‹åŠ¿å¹¶æä¾›å»ºè®®ï¼š

ä»“åº“ï¼š{repo.get('name', 'Unknown')}
åˆ†ææœŸé—´ï¼š{period.get('type', 'daily')} æŠ¥å‘Š

å¼€å‘æ´»åŠ¨ç»Ÿè®¡ï¼š
- æ´»è·ƒæäº¤è€…ï¼š{len(committers)} äºº
- ä»£ç æäº¤ï¼š{len(commits)} æ¬¡
- æ–°å¢Issuesï¼š{len(issues)} ä¸ªï¼ˆå¼€æ”¾ï¼š{open_issues}ï¼Œå·²å…³é—­ï¼š{closed_issues}ï¼‰
- Pull Requestsï¼š{len(prs)} ä¸ªï¼ˆå¼€æ”¾ï¼š{open_prs}ï¼Œå·²åˆå¹¶ï¼š{merged_prs}ï¼‰

{commits_detail}
{issues_detail}
{prs_detail}

è¯·åŸºäºä»¥ä¸Šè¯¦ç»†ä¿¡æ¯ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š
1. å¼€å‘æ´»è·ƒåº¦è¶‹åŠ¿
2. ä»£ç è´¨é‡å’Œç»´æŠ¤æƒ…å†µ
3. ç¤¾åŒºå‚ä¸åº¦
4. æ”¹è¿›å»ºè®®

è¯·ç”¨2-3æ®µè¯æ€»ç»“ï¼Œæ¯æ®µä¸è¶…è¿‡50å­—ã€‚
"""
        return prompt

    def _generate_simple_repository_summary(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€å•çš„ä»“åº“æ‘˜è¦"""
        repo = analysis_data.get('repository', {})
        commits = analysis_data.get('commits', [])
        issues = analysis_data.get('issues', [])
        prs = analysis_data.get('pull_requests', [])
        releases = analysis_data.get('releases', [])
        
        summary_parts = []
        
        if commits:
            summary_parts.append(f"æ–°å¢ {len(commits)} ä¸ªæäº¤")
        if issues:
            summary_parts.append(f"{len(issues)} ä¸ªIssuesæ´»åŠ¨")
        if prs:
            summary_parts.append(f"{len(prs)} ä¸ªPull Request")
        if releases:
            summary_parts.append(f"{len(releases)} ä¸ªæ–°å‘å¸ƒ")
        
        if summary_parts:
            summary = f"æœ¬æœŸé—´ {repo.get('name', 'è¯¥ä»“åº“')} æœ‰" + "ã€".join(summary_parts) + "ã€‚"
        else:
            summary = f"æœ¬æœŸé—´ {repo.get('name', 'è¯¥ä»“åº“')} æ²¡æœ‰æ–°çš„æ´»åŠ¨ã€‚"
        
        return summary

    def _generate_simple_trend_analysis(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€å•çš„è¶‹åŠ¿åˆ†æ"""
        commits = analysis_data.get('commits', [])
        issues = analysis_data.get('issues', [])
        prs = analysis_data.get('pull_requests', [])
        
        analysis_parts = []
        
        if len(commits) > 10:
            analysis_parts.append("ä»£ç æäº¤é¢‘ç¹ï¼Œå¼€å‘æ´»è·ƒåº¦è¾ƒé«˜")
        elif len(commits) > 0:
            analysis_parts.append("æœ‰é€‚é‡çš„ä»£ç æäº¤ï¼Œå¼€å‘ç¨³å®šè¿›è¡Œ")
        else:
            analysis_parts.append("æœ¬æœŸé—´ä»£ç æäº¤è¾ƒå°‘")
        
        if len(issues) > 5:
            analysis_parts.append("Issuesæ´»åŠ¨æ´»è·ƒï¼Œç¤¾åŒºå‚ä¸åº¦è‰¯å¥½")
        elif len(issues) > 0:
            analysis_parts.append("æœ‰ä¸€å®šçš„Issuesæ´»åŠ¨")
        
        if len(prs) > 3:
            analysis_parts.append("Pull Requestæ•°é‡è¾ƒå¤šï¼Œä»£ç åä½œè‰¯å¥½")
        elif len(prs) > 0:
            analysis_parts.append("æœ‰ä»£ç è´¡çŒ®å’Œåä½œ")
        
        if analysis_parts:
            analysis = "ã€‚".join(analysis_parts) + "ã€‚å»ºè®®ç»§ç»­ä¿æŒå½“å‰çš„å¼€å‘èŠ‚å¥ï¼Œå…³æ³¨ä»£ç è´¨é‡å’Œæ–‡æ¡£å®Œå–„ã€‚"
        else:
            analysis = "æœ¬æœŸé—´æ´»åŠ¨è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ å¼€å‘æ´»è·ƒåº¦ï¼Œé¼“åŠ±ç¤¾åŒºå‚ä¸ã€‚"
        
        return analysis
    
    def _prepare_analysis_data(
        self, 
        repository_data: Dict[str, Any], 
        activities: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """å‡†å¤‡ç”¨äºAIåˆ†æçš„æ•°æ®"""
        
        # ç»Ÿè®¡æ´»åŠ¨ç±»å‹
        activity_stats = {}
        for activity in activities:
            activity_type = activity.get("activity_type", "unknown")
            activity_stats[activity_type] = activity_stats.get(activity_type, 0) + 1
        
        # æå–å…³é”®æ´»åŠ¨
        key_activities = []
        for activity in activities[:10]:  # å–å‰10ä¸ªæ´»åŠ¨
            key_activities.append({
                "type": activity.get("activity_type"),
                "title": activity.get("title", "")[:100],
                "author": activity.get("author_login"),
                "created_at": activity.get("github_created_at")
            })
        
        return {
            "repository": {
                "name": repository_data.get("repository", "Unknown"),
                "description": repository_data.get("description", ""),
                "language": repository_data.get("language", ""),
                "stars": repository_data.get("stargazers_count", 0),
                "forks": repository_data.get("forks_count", 0)
            },
            "period_summary": {
                "total_activities": len(activities),
                "activity_types": activity_stats,
                "key_activities": key_activities
            }
        }
    
    async def _generate_openai_summary(self, analysis_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨ OpenAI API ç”Ÿæˆæ‘˜è¦"""
        if not self.ai_config.openai_api_key:
            logger.warning("OpenAI API Key æœªé…ç½®ï¼Œä½¿ç”¨ç®€å•æ‘˜è¦")
            return self._generate_simple_summary(analysis_data)
        
        try:
            prompt = self._create_summary_prompt(analysis_data)
            logger.info("ğŸ¤– å¼€å§‹è°ƒç”¨ OpenAI API ç”Ÿæˆæ‘˜è¦")
            logger.info(f"ğŸ“ ä½¿ç”¨æ¨¡å‹: {self.ai_config.openai_model}")
            logger.info(f"ğŸ¯ æœ€å¤§Tokenæ•°: {self.ai_config.max_tokens}")
            logger.info(f"ğŸŒ¡ï¸ æ¸©åº¦å‚æ•°: {self.ai_config.temperature}")
            logger.debug(f"ğŸ“‹ è¾“å…¥æç¤ºè¯:\n{prompt}")
            
            request_data = {
                "model": self.ai_config.openai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„GitHubä»“åº“æ´»åŠ¨åˆ†æå¸ˆï¼Œæ“…é•¿æ€»ç»“å¼€å‘æ´»åŠ¨å¹¶æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": self.ai_config.max_tokens,
                "temperature": self.ai_config.temperature
            }
            
            logger.debug(f"ğŸ“¤ å‘é€è¯·æ±‚æ•°æ®: {json.dumps(request_data, ensure_ascii=False, indent=2)}")
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.ai_config.openai_api_key[:10]}...{self.ai_config.openai_api_key[-4:]}",
                        "Content-Type": "application/json"
                    },
                    json=request_data,
                    timeout=30.0
                )
                
                logger.info(f"ğŸ“¡ OpenAI API å“åº”çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    logger.debug(f"ğŸ“¥ å®Œæ•´å“åº”æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
                    
                    summary = result["choices"][0]["message"]["content"].strip()
                    usage = result.get("usage", {})
                    
                    logger.info(f"âœ… OpenAI æ‘˜è¦ç”ŸæˆæˆåŠŸ")
                    logger.info(f"ğŸ“Š Tokenä½¿ç”¨æƒ…å†µ: è¾“å…¥={usage.get('prompt_tokens', 0)}, è¾“å‡º={usage.get('completion_tokens', 0)}, æ€»è®¡={usage.get('total_tokens', 0)}")
                    logger.info(f"ğŸ“ ç”Ÿæˆçš„æ‘˜è¦é•¿åº¦: {len(summary)} å­—ç¬¦")
                    logger.debug(f"ğŸ“„ ç”Ÿæˆçš„æ‘˜è¦å†…å®¹:\n{summary}")
                    
                    return summary
                else:
                    error_text = response.text
                    logger.error(f"ğŸ’¥ OpenAI API è¯·æ±‚å¤±è´¥: {response.status_code}")
                    logger.error(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {error_text}")
                    return self._generate_simple_summary(analysis_data)
                    
        except Exception as e:
            logger.error(f"ğŸ’¥ OpenAI æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            return self._generate_simple_summary(analysis_data)
    
    async def _generate_ollama_summary(self, analysis_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨ Ollama ç”Ÿæˆæ‘˜è¦"""
        try:
            prompt = self._create_summary_prompt(analysis_data)
            logger.info("ğŸ¤– å¼€å§‹è°ƒç”¨ Ollama API ç”Ÿæˆæ‘˜è¦")
            logger.info(f"ğŸŒ Ollama URL: {self.ai_config.ollama_url}")
            logger.info(f"ğŸ“ ä½¿ç”¨æ¨¡å‹: {self.ai_config.ollama_model}")
            logger.info(f"ğŸ¯ æœ€å¤§Tokenæ•°: {self.ai_config.max_tokens}")
            logger.info(f"ğŸŒ¡ï¸ æ¸©åº¦å‚æ•°: {self.ai_config.temperature}")
            logger.debug(f"ğŸ“‹ è¾“å…¥æç¤ºè¯:\n{prompt}")
            
            request_data = {
                "model": self.ai_config.ollama_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": self.ai_config.temperature,
                    "num_predict": self.ai_config.max_tokens
                }
            }
            
            logger.debug(f"ğŸ“¤ å‘é€è¯·æ±‚æ•°æ®: {json.dumps(request_data, ensure_ascii=False, indent=2)}")
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.ai_config.ollama_url}/api/generate",
                    json=request_data,
                    timeout=60.0
                )
                
                logger.info(f"ğŸ“¡ Ollama API å“åº”çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    logger.debug(f"ğŸ“¥ å®Œæ•´å“åº”æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
                    
                    summary = result["response"].strip()
                    
                    logger.info(f"âœ… Ollama æ‘˜è¦ç”ŸæˆæˆåŠŸ")
                    logger.info(f"ğŸ“ ç”Ÿæˆçš„æ‘˜è¦é•¿åº¦: {len(summary)} å­—ç¬¦")
                    logger.debug(f"ğŸ“„ ç”Ÿæˆçš„æ‘˜è¦å†…å®¹:\n{summary}")
                    
                    return summary
                else:
                    error_text = response.text
                    logger.error(f"ğŸ’¥ Ollama API è¯·æ±‚å¤±è´¥: {response.status_code}")
                    logger.error(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {error_text}")
                    return self._generate_simple_summary(analysis_data)
                    
        except Exception as e:
            logger.error(f"ğŸ’¥ Ollama æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            return self._generate_simple_summary(analysis_data)
    
    def _create_summary_prompt(self, analysis_data: Dict[str, Any]) -> str:
        """åˆ›å»ºæ‘˜è¦ç”Ÿæˆçš„æç¤ºè¯"""
        repo_info = analysis_data["repository"]
        period_summary = analysis_data["period_summary"]
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹GitHubä»“åº“æ´»åŠ¨ç”Ÿæˆä¸€ä»½ç®€æ´è€Œæœ‰ä»·å€¼çš„ä¸­æ–‡æ‘˜è¦ï¼š

ä»“åº“ä¿¡æ¯ï¼š
- åç§°ï¼š{repo_info["name"]}
- æè¿°ï¼š{repo_info["description"]}
- ä¸»è¦è¯­è¨€ï¼š{repo_info["language"]}
- Starsï¼š{repo_info["stars"]}
- Forksï¼š{repo_info["forks"]}

æ´»åŠ¨ç»Ÿè®¡ï¼š
- æ€»æ´»åŠ¨æ•°ï¼š{period_summary["total_activities"]}
- æ´»åŠ¨ç±»å‹åˆ†å¸ƒï¼š{json.dumps(period_summary["activity_types"], ensure_ascii=False)}

ä¸»è¦æ´»åŠ¨ï¼š
"""
        
        for activity in period_summary["key_activities"]:
            prompt += f"- {activity['type']}: {activity['title']} (by {activity['author']})\n"
        
        prompt += """
è¯·ç”Ÿæˆä¸€ä»½200-300å­—çš„æ‘˜è¦ï¼ŒåŒ…æ‹¬ï¼š
1. æœ¬æœŸé—´çš„ä¸»è¦å¼€å‘æ´»åŠ¨æ¦‚è¿°
2. å€¼å¾—å…³æ³¨çš„é‡è¦å˜åŒ–æˆ–è¶‹åŠ¿
3. å¯¹é¡¹ç›®å‘å±•çš„ç®€è¦è¯„ä»·

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡
- è¯­è¨€ç®€æ´ä¸“ä¸š
- çªå‡ºé‡ç‚¹ä¿¡æ¯
- é¿å…è¿‡äºæŠ€æœ¯æ€§çš„ç»†èŠ‚
"""
        
        return prompt
    
    def _generate_simple_summary(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€å•çš„ç»Ÿè®¡æ‘˜è¦ï¼ˆä¸ä½¿ç”¨AIï¼‰"""
        repo_info = analysis_data["repository"]
        period_summary = analysis_data["period_summary"]
        
        summary_parts = []
        
        # åŸºæœ¬ç»Ÿè®¡
        total_activities = period_summary["total_activities"]
        summary_parts.append(f"æœ¬æœŸé—´ {repo_info['name']} ä»“åº“å…±æœ‰ {total_activities} é¡¹æ´»åŠ¨ã€‚")
        
        # æ´»åŠ¨ç±»å‹ç»Ÿè®¡
        activity_types = period_summary["activity_types"]
        if activity_types:
            type_descriptions = {
                "commit": "ä»£ç æäº¤",
                "issue": "é—®é¢˜è®¨è®º",
                "pull_request": "ä»£ç åˆå¹¶è¯·æ±‚",
                "release": "ç‰ˆæœ¬å‘å¸ƒ"
            }
            
            type_summary = []
            for activity_type, count in activity_types.items():
                desc = type_descriptions.get(activity_type, activity_type)
                type_summary.append(f"{desc} {count} é¡¹")
            
            summary_parts.append(f"å…¶ä¸­åŒ…æ‹¬ï¼š{', '.join(type_summary)}ã€‚")
        
        # ä¸»è¦æ´»åŠ¨
        key_activities = period_summary["key_activities"]
        if key_activities:
            summary_parts.append("ä¸»è¦æ´»åŠ¨åŒ…æ‹¬ï¼š")
            for activity in key_activities[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                summary_parts.append(f"â€¢ {activity['title']} (by {activity['author']})")
        
        # é¡¹ç›®ä¿¡æ¯
        if repo_info.get("language"):
            summary_parts.append(f"è¯¥é¡¹ç›®ä¸»è¦ä½¿ç”¨ {repo_info['language']} è¯­è¨€å¼€å‘ã€‚")
        
        return "\n".join(summary_parts)
    
    async def generate_trend_analysis(
        self, 
        historical_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆè¶‹åŠ¿åˆ†æ
        
        Args:
            historical_data: å†å²æ•°æ®åˆ—è¡¨
        
        Returns:
            Dict[str, Any]: è¶‹åŠ¿åˆ†æç»“æœ
        """
        if len(historical_data) < 2:
            return {
                "trend": "insufficient_data",
                "description": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ",
                "recommendations": []
            }
        
        # è®¡ç®—æ´»åŠ¨è¶‹åŠ¿
        activity_counts = [data.get("total_activities", 0) for data in historical_data]
        
        # ç®€å•çš„è¶‹åŠ¿è®¡ç®—
        recent_avg = sum(activity_counts[-3:]) / min(3, len(activity_counts))
        earlier_avg = sum(activity_counts[:-3]) / max(1, len(activity_counts) - 3)
        
        if recent_avg > earlier_avg * 1.2:
            trend = "increasing"
            description = "é¡¹ç›®æ´»åŠ¨å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå¼€å‘è¾ƒä¸ºæ´»è·ƒ"
        elif recent_avg < earlier_avg * 0.8:
            trend = "decreasing"
            description = "é¡¹ç›®æ´»åŠ¨æœ‰æ‰€ä¸‹é™ï¼Œå¯èƒ½éœ€è¦å…³æ³¨"
        else:
            trend = "stable"
            description = "é¡¹ç›®æ´»åŠ¨ä¿æŒç¨³å®š"
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(trend, historical_data)
        
        return {
            "trend": trend,
            "description": description,
            "recent_average": recent_avg,
            "earlier_average": earlier_avg,
            "recommendations": recommendations
        }
    
    def _generate_recommendations(
        self, 
        trend: str, 
        historical_data: List[Dict[str, Any]]
    ) -> List[str]:
        """æ ¹æ®è¶‹åŠ¿ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if trend == "increasing":
            recommendations.extend([
                "é¡¹ç›®å‘å±•åŠ¿å¤´è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒ",
                "å¯ä»¥è€ƒè™‘å¢åŠ ä»£ç å®¡æŸ¥å’Œè´¨é‡æ§åˆ¶",
                "å…³æ³¨æ–°è´¡çŒ®è€…çš„å‚ä¸æƒ…å†µ"
            ])
        elif trend == "decreasing":
            recommendations.extend([
                "å»ºè®®åˆ†ææ´»åŠ¨ä¸‹é™çš„åŸå› ",
                "å¯ä»¥è€ƒè™‘å¢åŠ ç¤¾åŒºäº’åŠ¨å’Œå®£ä¼ ",
                "æ£€æŸ¥æ˜¯å¦æœ‰æŠ€æœ¯å€ºåŠ¡æˆ–é˜»ç¢å› ç´ "
            ])
        else:
            recommendations.extend([
                "é¡¹ç›®ä¿æŒç¨³å®šå‘å±•",
                "å¯ä»¥è€ƒè™‘è®¾å®šæ–°çš„å‘å±•ç›®æ ‡",
                "æŒç»­å…³æ³¨ä»£ç è´¨é‡å’Œæ–‡æ¡£å®Œå–„"
            ])
        
        return recommendations
    
    async def generate_activity_insights(
        self, 
        activities: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ´»åŠ¨æ´å¯Ÿ
        
        Args:
            activities: æ´»åŠ¨åˆ—è¡¨
        
        Returns:
            Dict[str, Any]: æ´»åŠ¨æ´å¯Ÿç»“æœ
        """
        if not activities:
            return {
                "insights": [],
                "top_contributors": [],
                "activity_patterns": {}
            }
        
        # åˆ†æè´¡çŒ®è€…
        contributors = {}
        for activity in activities:
            author = activity.get("author_login", "unknown")
            contributors[author] = contributors.get(author, 0) + 1
        
        top_contributors = sorted(
            contributors.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]
        
        # åˆ†ææ´»åŠ¨æ¨¡å¼
        activity_patterns = {}
        for activity in activities:
            activity_type = activity.get("activity_type", "unknown")
            activity_patterns[activity_type] = activity_patterns.get(activity_type, 0) + 1
        
        # ç”Ÿæˆæ´å¯Ÿ
        insights = []
        
        if top_contributors:
            top_contributor = top_contributors[0]
            insights.append(f"æœ€æ´»è·ƒçš„è´¡çŒ®è€…æ˜¯ {top_contributor[0]}ï¼Œå…±æœ‰ {top_contributor[1]} é¡¹æ´»åŠ¨")
        
        if len(contributors) > 1:
            insights.append(f"æœ¬æœŸé—´å…±æœ‰ {len(contributors)} ä½è´¡çŒ®è€…å‚ä¸")
        
        most_common_activity = max(activity_patterns.items(), key=lambda x: x[1])
        insights.append(f"æœ€å¸¸è§çš„æ´»åŠ¨ç±»å‹æ˜¯ {most_common_activity[0]}ï¼Œå  {most_common_activity[1]} é¡¹")
        
        return {
            "insights": insights,
            "top_contributors": top_contributors,
            "activity_patterns": activity_patterns,
            "total_contributors": len(contributors)
        } 